{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Research Field Classifier ([Source](https://gitlab.com/TIBHannover/orkg/nlp/experiments/orkg-research-fields-classifier/-/blob/master/notebooks/train_eval_notebook.ipynb))\n",
    "\n",
    "This notebook trains a model to classify research fields of research papers. The model is trained on the ORKG dataset and is based on the [SciNCL model](https://huggingface.co/malteos/scincl)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.join('..', '..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "orkg_file = os.path.join(data_dir, 'orkg', 'orkg_data.csv')\n",
    "\n",
    "#\n",
    "# Model\n",
    "#\n",
    "\n",
    "model_dir = os.path.join(base_dir, 'models', 'scincl_single_label_classifier')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#\n",
    "# Data\n",
    "#\n",
    "\n",
    "train_file = os.path.join(data_dir, 'scincl_classifier', 'single_label_test.csv')\n",
    "test_file = os.path.join(data_dir, 'scincl_classifier', 'single_label_train.csv')\n",
    "os.makedirs(os.path.dirname(train_file), exist_ok=True)\n",
    "\n",
    "#\n",
    "# Reports\n",
    "#\n",
    "\n",
    "evaluation_dir = os.path.join(base_dir, 'reports', 'orkg', 'scincl_classifier')\n",
    "os.makedirs(evaluation_dir, exist_ok=True)\n",
    "\n",
    "predictions_file = os.path.join(evaluation_dir, f'single_label_evaluation.csv')\n",
    "evaluation_file = os.path.join(evaluation_dir, f'single_label_evaluation.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJbanBAH5H3B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn223-LX5H3C"
   },
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7YAwJHH5H3D",
    "outputId": "df02d0a5-661a-4f32-a9e6-303c9c907768"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('malteos/scincl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(orkg_file)\n",
    "\n",
    "# Rename \"research field\" to \"label\"\n",
    "df = df.rename(columns={\"research field\": \"label\"})\n",
    "\n",
    "df = df[[\"title\", \"abstract\", \"label\"]]\n",
    "df[\"abstract\"] = [\"\" if pd.isna(abstract) else abstract for abstract in df[\"abstract\"]]\n",
    "df[\"text\"] = [str(row[\"title\"]) + tokenizer.sep_token + (row[\"abstract\"] or \"\") for index, row in df.iterrows()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(train_file, index=False)\n",
    "test_df.to_csv(test_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Mapping of labels to integers\n",
    "labels = list(set(df[\"label\"].unique()))\n",
    "label_dict = {label: i for i, label in enumerate(labels)}\n",
    "reverse_label_dict = {v: k for k, v in label_dict.items()}"
   ],
   "metadata": {
    "id": "GqNmQ1HC5xGv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_df = train_df[[\"text\", \"label\"]]\n",
    "test_df = test_df[[\"text\", \"label\"]]\n",
    "\n",
    "train_df[\"label\"] = [label_dict[label] for label in train_df[\"label\"]]\n",
    "test_df[\"label\"] = [label_dict[label] for label in test_df[\"label\"]]\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dd = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ],
   "metadata": {
    "id": "3BbOnCNt6ATD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X92NoiK5H3P"
   },
   "source": [
    "#### Tokenize the text in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juqUjGOM5H3P"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    # pad the attention masks to the same length as the input sequences\n",
    "    tokenized['attention_mask'] = [\n",
    "        torch.cat([\n",
    "            torch.tensor(mask),\n",
    "            torch.zeros(512 - len(mask))\n",
    "        ])\n",
    "        for mask in tokenized['attention_mask']\n",
    "    ]\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pg36uop_5H3Q",
    "outputId": "2e332f5a-be36-453d-a121-da985a2593eb"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = dd.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RncwLTNu5H3Q",
    "outputId": "35ac274c-b860-4278-f33c-12785ee20064"
   },
   "outputs": [],
   "source": [
    "# Remove __index_level_0__ column\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\"__index_level_0__\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW7MwaPL5H3R"
   },
   "source": [
    "#### Preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FhbPrf75H3R"
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns from dataset\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmXVg3Y95H3R"
   },
   "outputs": [],
   "source": [
    "# rename the label column to labels because the model expects the argument to be named as the latter\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFOI6WQe5H3S"
   },
   "outputs": [],
   "source": [
    "# set the format of the dataset to return PyTorch instrad og lists\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlvZVs715H3S",
    "outputId": "0074b1c4-34b9-4d12-b487-6d635e025792"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAh_ZDN65H3T"
   },
   "source": [
    "### Training with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEKkBPNV5H3T"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoader objects to iterate over batches of data when training\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=30)\n",
    "test_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pTgWXgu5H3T",
    "outputId": "a49db9cc-7cdf-4043-ec29-6c2e308d8744"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# get the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"malteos/scincl\",\n",
    "    num_labels=len(label_dict)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyMMdec55H3T"
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# define optimizer with the learning rate and the scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i93rIJFz5H3U"
   },
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r19J1JAd5H3V",
    "outputId": "593b8f33-c637-44fb-a950-16930364a28b"
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMkxEtPK5H3V",
    "outputId": "de6e6dab-5b56-4a21-eaf4-e0b51e93fa0d"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "model.save_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsft3e9b5H3W"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mSjfd-R5H3W"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeUKcQJ05H3X"
   },
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(len(test_dataloader)))\n",
    "\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_df = test_df.copy()\n",
    "\n",
    "predicted_labels = [reverse_label_dict[label] for label in predictions]\n",
    "gt_labels = [reverse_label_dict[label] for label in final_df[\"label\"]]\n",
    "\n",
    "final_df[\"label\"] = gt_labels\n",
    "final_df[\"predicted_labels\"] = predicted_labels\n",
    "final_df.to_csv(predictions_file, index=False)\n",
    "\n",
    "final_df"
   ],
   "metadata": {
    "id": "Yyfwf-gEHhxp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(gt_labels, predicted_labels)\n",
    "precision = precision_score(gt_labels, predicted_labels, average=\"micro\")\n",
    "recall = recall_score(gt_labels, predicted_labels, average=\"micro\")\n",
    "f1 = f1_score(gt_labels, predicted_labels, average=\"micro\")\n",
    "\n",
    "evaluation_results = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1\n",
    "}\n",
    "\n",
    "# Write evaluation results to file\n",
    "with open(evaluation_file, \"w\") as file:\n",
    "    json.dump(evaluation_results, file, indent=2)\n",
    "\n",
    "evaluation_results"
   ],
   "metadata": {
    "id": "fITUh_woIEfM"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
