{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create OpenAI fine-tuning prompts and completions\n",
    "\n",
    "This notebook creates prompts and completions for research object classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = os.path.join('..', '..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "bibtext_file = os.path.join(data_dir, 'software_architecture', 'bib-text.csv')\n",
    "\n",
    "taxonomy_file = os.path.join(data_dir, 'software_architecture', 'taxonomy_explanation.json')\n",
    "\n",
    "output_dir = os.path.join(data_dir, 'openai_fine_tune')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(bibtext_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create prompts and completions for openai fine-tuning\n",
    "\n",
    "* **Prompts** are created by concatenating the title and abstract of a paper.\n",
    "* **Completions** are JSON objects that contain the research fields and explanations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from treelib import Tree\n",
    "\n",
    "\n",
    "def get_research_objects(tree: Tree) -> List[str]:\n",
    "    research_obj = tree.children(\"Research Object\")\n",
    "\n",
    "    objs = []\n",
    "    for obj in research_obj:\n",
    "        objs.append(obj.tag)\n",
    "\n",
    "    return objs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.utils.utils_json import read_json\n",
    "\n",
    "taxonomy_explanation = read_json(taxonomy_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from src.taxonomy.utils import parse_taxonomy\n",
    "\n",
    "openai_prompts = []\n",
    "openai_completions = []\n",
    "\n",
    "for inx, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    abstract = row['abstract']\n",
    "    classes = row['classes']\n",
    "\n",
    "    taxonomy = parse_taxonomy(classes)\n",
    "    classifications = get_research_objects(taxonomy)\n",
    "\n",
    "    prompt = f\"{title}\\n\\n{abstract}\\n\\n\"\n",
    "    completion = {\n",
    "        \"Research Object\": classifications,\n",
    "        \"Explanations\": {},\n",
    "    }\n",
    "\n",
    "    obj_explanations = taxonomy_explanation[\"Research Object\"]\n",
    "    for clazz in classifications:\n",
    "        if clazz in obj_explanations:\n",
    "            completion[\"Explanations\"][clazz] = obj_explanations[clazz]\n",
    "\n",
    "    openai_prompts.append(prompt)\n",
    "    openai_completions.append(json.dumps(completion, sort_keys=True))\n",
    "\n",
    "openai_df = pd.DataFrame({\n",
    "    'prompt': openai_prompts,\n",
    "    'completion': openai_completions\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for fine-tuning\n",
    "\n",
    "* Each completion should begin with a whitespace\n",
    "* Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "* Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n.\n",
    "* Remove rows where the promt is longer than 2048 characters\n",
    "* Split into train and test\n",
    "* Print commands to run in OpenAI cli\n",
    "\n",
    "[OpenAI's dataset preparation guide](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Each completion should begin with a whitespace\n",
    "openai_df['completion'] = openai_df['completion'].apply(lambda x: ' ' + x)\n",
    "\n",
    "# Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "openai_df['completion'] = openai_df['completion'].apply(lambda x: x + '\\n')\n",
    "\n",
    "# Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n.\n",
    "openai_df['prompt'] = openai_df['prompt'].apply(lambda x: x + '\\n\\n###\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows where the promt is longer than 2048 characters\n",
    "openai_df = openai_df[openai_df['prompt'].str.len() < 2048]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from names_generator import generate_name\n",
    "\n",
    "model_name = generate_name()\n",
    "print('Model name:', model_name)\n",
    "\n",
    "openai_df.to_csv(os.path.join(output_dir, model_name + \".csv\"), index=False)\n",
    "\n",
    "train_df, test_df = train_test_split(openai_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_file = os.path.join(output_dir, model_name + \"_train.jsonl\")\n",
    "train_df.to_json(train_file, orient='records', lines=True)\n",
    "\n",
    "test_file = os.path.join(output_dir, model_name + \"_test.jsonl\")\n",
    "test_df.to_json(test_file, orient='records', lines=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print commands to run in OpenAI cli\n",
    "\n",
    "This section prints the commands that need to be run in on the command line to fine-tune the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !openai tools fine_tunes.prepare_data -f {model_name}_train.jsonl\n",
    "print(f\"cd {dir};\\n\"\n",
    "      f\"openai tools fine_tunes.prepare_data -f {model_name}_train.jsonl;\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "openai_models = [\n",
    "    'ada',\n",
    "    'babbage',\n",
    "    'curie',\n",
    "    'davinci'\n",
    "]\n",
    "\n",
    "for openai_model in openai_models:\n",
    "    print(f\"openai api fine_tunes.create -t \\\"{model_name}_train.jsonl\\\" --suffix {model_name} -m {openai_model}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
