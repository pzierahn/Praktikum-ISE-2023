{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Clustering of Research Papers\n",
    "\n",
    "This notebook demonstrates how to perform hierarchical clustering of research papers based on their abstracts. The research papers are clustered based on their titles and abstracts using hierarchical clustering. The clustering is then compared with the ground truth labels to evaluate the performance of the clustering algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.join('..', '..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "orkg_file = os.path.join(data_dir, 'orkg', 'orkg_data.csv')\n",
    "\n",
    "evaluation_dir = os.path.join(base_dir, 'reports', 'scincl_clustering')\n",
    "os.makedirs(evaluation_dir, exist_ok=True)\n",
    "\n",
    "sample_df_file = os.path.join(evaluation_dir, 'sample_df.csv')\n",
    "labels_file = os.path.join(evaluation_dir, 'labels.json')\n",
    "evaluation_file = os.path.join(evaluation_dir, 'evaluation.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:19.288248Z",
     "start_time": "2023-09-16T19:05:19.255833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Torch device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('malteos/scincl', num_workers=os.cpu_count())\n",
    "model = AutoModel.from_pretrained('malteos/scincl').to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:20.870534Z",
     "start_time": "2023-09-16T19:05:19.262103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "            id                                              title  \\\n0      R209491  Knowledge management framework for monitoring ...   \n2      R504922  A Strong Baseline for Fashion Retrieval with P...   \n8      R422258  End-to-End Human Pose and Mesh Reconstruction ...   \n9      R518734  IPOD: Intensive Point-based Object Detector fo...   \n13     R449385  SqueezeSeg: Convolutional Neural Nets with Rec...   \n...        ...                                                ...   \n26735  R597298  Dual Temperature Helps Contrastive Learning Wi...   \n26739  R160334  Product recovery decisions within the context ...   \n26741  R521270  Comprehensive Attention Self-Distillation for ...   \n26742  R554286  How Do Graph Networks Generalize to Large and ...   \n26743  R532777  Improving the Gating Mechanism of Recurrent Ne...   \n\n                                      doi  \\\n0            [10.1109/EESMS.2015.7175848]   \n2                                      []   \n8                                      []   \n9                                      []   \n13                                     []   \n...                                   ...   \n26735                                  []   \n26739  [10.1016/j.jengtecman.2013.11.002]   \n26741                                  []   \n26742                                  []   \n26743                                  []   \n\n                                          research field  \\\n0                                   Computer Engineering   \n2                                      Computer Sciences   \n8                                      Computer Sciences   \n9                                      Computer Sciences   \n13                                     Computer Sciences   \n...                                                  ...   \n26735                  Computer and Systems Architecture   \n26739  Information Systems, Process and Knowledge Man...   \n26741                                  Computer Sciences   \n26742                                  Computer Sciences   \n26743                                  Computer Sciences   \n\n                                               subfields  \\\n0      [Robotics, Digital Circuits, Data Storage Syst...   \n2      [Security and Dependability, Computer Architec...   \n8      [Security and Dependability, Computer Architec...   \n9      [Security and Dependability, Computer Architec...   \n13     [Security and Dependability, Computer Architec...   \n...                                                  ...   \n26735                                                 []   \n26739                                                 []   \n26741  [Security and Dependability, Computer Architec...   \n26742  [Security and Dependability, Computer Architec...   \n26743  [Security and Dependability, Computer Architec...   \n\n                                                abstract  \n0      In the last decades scarcity of resources and ...  \n2                                                         \n8                                                         \n9                                                         \n13                                                        \n...                                                  ...  \n26735                                                     \n26739                                                     \n26741                                                     \n26742                                                     \n26743                                                     \n\n[14305 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>doi</th>\n      <th>research field</th>\n      <th>subfields</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>R209491</td>\n      <td>Knowledge management framework for monitoring ...</td>\n      <td>[10.1109/EESMS.2015.7175848]</td>\n      <td>Computer Engineering</td>\n      <td>[Robotics, Digital Circuits, Data Storage Syst...</td>\n      <td>In the last decades scarcity of resources and ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>R504922</td>\n      <td>A Strong Baseline for Fashion Retrieval with P...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>R422258</td>\n      <td>End-to-End Human Pose and Mesh Reconstruction ...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>R518734</td>\n      <td>IPOD: Intensive Point-based Object Detector fo...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>R449385</td>\n      <td>SqueezeSeg: Convolutional Neural Nets with Rec...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26735</th>\n      <td>R597298</td>\n      <td>Dual Temperature Helps Contrastive Learning Wi...</td>\n      <td>[]</td>\n      <td>Computer and Systems Architecture</td>\n      <td>[]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>26739</th>\n      <td>R160334</td>\n      <td>Product recovery decisions within the context ...</td>\n      <td>[10.1016/j.jengtecman.2013.11.002]</td>\n      <td>Information Systems, Process and Knowledge Man...</td>\n      <td>[]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>26741</th>\n      <td>R521270</td>\n      <td>Comprehensive Attention Self-Distillation for ...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>26742</th>\n      <td>R554286</td>\n      <td>How Do Graph Networks Generalize to Large and ...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>26743</th>\n      <td>R532777</td>\n      <td>Improving the Gating Mechanism of Recurrent Ne...</td>\n      <td>[]</td>\n      <td>Computer Sciences</td>\n      <td>[Security and Dependability, Computer Architec...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>14305 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a random sample of 5 rows\n",
    "df = pd.read_csv(orkg_file)\n",
    "df[\"doi\"] = df.doi.apply(eval).apply(np.array)  # convert string to array\n",
    "df[\"subfields\"] = df.subfields.apply(eval).apply(np.array)  # convert string to array\n",
    "df = df.fillna('')\n",
    "\n",
    "# Remove rows where the title is less than 5 characters\n",
    "df = df[df['title'].str.len() > 35]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:24.946143Z",
     "start_time": "2023-09-16T19:05:20.871469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df['text'] = df['title']\n",
    "\n",
    "for inx, row in df.iterrows():\n",
    "    if row['abstract'] != '':\n",
    "        df['text'][inx] += tokenizer.sep_token + row['abstract']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:25.428483Z",
     "start_time": "2023-09-16T19:05:24.950066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=200, random_state=420)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:25.432403Z",
     "start_time": "2023-09-16T19:05:25.430012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "label_unique = sample_df['research field'].unique()\n",
    "label_unique.sort()\n",
    "\n",
    "label_dict = {\n",
    "    label: i for i, label in enumerate(label_unique)\n",
    "}\n",
    "\n",
    "reverse_label_dict = {\n",
    "    v: k for k, v in label_dict.items()\n",
    "}\n",
    "\n",
    "# Map the labels to integers\n",
    "sample_df['label'] = sample_df['research field'].map(label_dict)\n",
    "\n",
    "# Save the sample dataframe\n",
    "sample_df.to_csv(sample_df_file, index=False)\n",
    "\n",
    "# Save the labels\n",
    "with open(labels_file, 'w') as file:\n",
    "    file.write(json.dumps(label_dict, indent=2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:25.476627Z",
     "start_time": "2023-09-16T19:05:25.434744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 25\n",
      "Labels: [ 3 19  8 21 14 20  0  6 17 13 11  7  9  4  2 23 18 10  1  5 12 15 24 16\n",
      " 22]\n"
     ]
    }
   ],
   "source": [
    "labels = sample_df['label'].unique()\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(\"Labels:\", labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:25.476931Z",
     "start_time": "2023-09-16T19:05:25.465162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Tokenize the 'text' column\n",
    "tokenized_inputs = tokenizer(\n",
    "    sample_df['text'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "# Convert tokenized inputs to tensors\n",
    "input_ids = tokenized_inputs['input_ids'].to(device)\n",
    "attention_mask = tokenized_inputs['attention_mask'].to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:05:25.516297Z",
     "start_time": "2023-09-16T19:05:25.473567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings: 100%|██████████| 25/25 [00:52<00:00,  2.10s/batch]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 8  # Specify the batch size\n",
    "\n",
    "# Split input tensors into batches\n",
    "input_ids_batches = input_ids.split(batch_size)\n",
    "attention_mask_batches = attention_mask.split(batch_size)\n",
    "\n",
    "embeddings = []  # List to store the embeddings\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=len(input_ids_batches), desc='Embeddings', unit='batch')\n",
    "\n",
    "# Iterate over each batch\n",
    "for input_ids_batch, attention_mask_batch in zip(input_ids_batches, attention_mask_batches):\n",
    "    # Move the batch to the appropriate device if using GPU\n",
    "    input_ids_batch = input_ids_batch.to(device)\n",
    "    attention_mask_batch = attention_mask_batch.to(device)\n",
    "\n",
    "    # Obtain embeddings for the batch\n",
    "    batch_embeddings = model(\n",
    "        input_ids=input_ids_batch,\n",
    "        attention_mask=attention_mask_batch\n",
    "    )\n",
    "\n",
    "    # Append batch embeddings to the list\n",
    "    embeddings.append(batch_embeddings[0].detach().cpu())\n",
    "\n",
    "    # Delete batch embeddings to avoid out of memory leaks\n",
    "    del batch_embeddings\n",
    "    del input_ids_batch\n",
    "    del attention_mask_batch\n",
    "\n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:06:17.930821Z",
     "start_time": "2023-09-16T19:05:25.508752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "embeddings_np = np.concatenate(embeddings, axis=0)\n",
    "del embeddings\n",
    "\n",
    "# Reshape the embeddings if necessary\n",
    "if embeddings_np.ndim > 1:\n",
    "    embeddings_np = embeddings_np.reshape(embeddings_np.shape[0], -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:06:18.027204Z",
     "start_time": "2023-09-16T19:06:17.932383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Split dataframes into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings_np, sample_df['label'], test_size=0.2, random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:17:42.247308Z",
     "start_time": "2023-09-16T19:17:42.198117Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:17:42.251025Z",
     "start_time": "2023-09-16T19:17:42.246353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "hierarchical_cluster = AgglomerativeClustering(\n",
    "    n_clusters=len(labels),\n",
    "    metric='euclidean',\n",
    "    linkage='ward'\n",
    ")\n",
    "\n",
    "_ = hierarchical_cluster.fit_predict(\n",
    "    X_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "hierarchical_pred = hierarchical_cluster.fit_predict(X_test, y=y_test)\n",
    "\n",
    "\n",
    "hierarchical_accuracy = accuracy_score(y_test, hierarchical_pred)\n",
    "hierarchical_precision = precision_score(y_test, hierarchical_pred, average=\"micro\")\n",
    "hierarchical_recall = recall_score(y_test, hierarchical_pred, average=\"micro\")\n",
    "hierarchical_f1 = f1_score(y_test, hierarchical_pred, average=\"micro\")\n",
    "\n",
    "evaluation_df.loc[len(evaluation_df)] = ['Hierarchical Clustering',\n",
    "                                         hierarchical_accuracy,\n",
    "                                         hierarchical_precision,\n",
    "                                         hierarchical_recall,\n",
    "                                         hierarchical_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:17:43.959709Z",
     "start_time": "2023-09-16T19:17:42.250561Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/Code/praktikum-ise-2023-patrick-zierahn/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=len(sample_df[\"label\"].unique()),\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    ")\n",
    "\n",
    "_ = kmeans.fit_predict(X_train, y=y_train)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Calculate Adjusted Rand Index (ARI) to compare the clustering with ground truth\n",
    "kmeans_pred = kmeans.predict(X_test)\n",
    "\n",
    "kmeans_accuracy = accuracy_score(y_test, kmeans_pred)\n",
    "kmeans_precision = precision_score(y_test, kmeans_pred, average=\"micro\")\n",
    "kmeans_recall = recall_score(y_test, kmeans_pred, average=\"micro\")\n",
    "kmeans_f1 = f1_score(y_test, kmeans_pred, average=\"micro\")\n",
    "\n",
    "evaluation_df.loc[len(evaluation_df)] = ['KMeans',\n",
    "                                         kmeans_accuracy,\n",
    "                                         kmeans_precision,\n",
    "                                         kmeans_recall,\n",
    "                                         kmeans_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:18:26.288970Z",
     "start_time": "2023-09-16T19:17:43.962766Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "forest_pred = clf.predict(X_test)\n",
    "\n",
    "forest_accuracy = accuracy_score(y_test, forest_pred)\n",
    "forest_precision = precision_score(y_test, forest_pred, average=\"micro\")\n",
    "forest_recall = recall_score(y_test, forest_pred, average=\"micro\")\n",
    "forest_f1 = f1_score(y_test, forest_pred, average=\"micro\")\n",
    "\n",
    "evaluation_df.loc[len(evaluation_df)] = ['Random Forest',\n",
    "                                         forest_accuracy,\n",
    "                                         forest_precision,\n",
    "                                         forest_recall,\n",
    "                                         forest_f1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:18:28.821035Z",
     "start_time": "2023-09-16T19:18:26.290234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "evaluation_df.to_csv(evaluation_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:18:28.824372Z",
     "start_time": "2023-09-16T19:18:28.821325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "                     Model  Accuracy  Precision  Recall     F1\n0  Hierarchical Clustering     0.025      0.025   0.025  0.025\n1                   KMeans     0.050      0.050   0.050  0.050\n2            Random Forest     0.650      0.650   0.650  0.650",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hierarchical Clustering</td>\n      <td>0.025</td>\n      <td>0.025</td>\n      <td>0.025</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KMeans</td>\n      <td>0.050</td>\n      <td>0.050</td>\n      <td>0.050</td>\n      <td>0.050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>0.650</td>\n      <td>0.650</td>\n      <td>0.650</td>\n      <td>0.650</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T19:18:28.830613Z",
     "start_time": "2023-09-16T19:18:28.826302Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
